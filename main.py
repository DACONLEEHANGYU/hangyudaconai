import os
import streamlit as st
from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langserve import RemoteRunnable
from utils import print_messages
from langchain_core.messages import ChatMessage


load_dotenv()
llm = RemoteRunnable(os.getenv('LANGSERVE_ENDPOINT'))

st.set_page_config(page_title="DaconInfinityGPT", page_icon="ğŸ”—")
st.title("DaconInfinityGPT")

if "messages" not in st.session_state:
  st.session_state["messages"] = []

# ì´ì „ ëŒ€í™”ê¸°ë¡ ì¶œë ¥
print_messages()

if user_input := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."):
  st.chat_message("user").write(f"{user_input}")
  st.session_state["messages"].append(ChatMessage(role="user", content=user_input))

  prompt = ChatPromptTemplate.from_template(
    """ì§ˆë¬¸ì— ëŒ€í•˜ì—¬ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.
    {question}
    """
  )
  chain = prompt | llm
  response = chain.invoke({"question": user_input})
  with st.chat_message("assistant"):
    msg = response.content

    st.write(msg)
    st.session_state["messages"].append(ChatMessage(role="assistant", content=msg))
